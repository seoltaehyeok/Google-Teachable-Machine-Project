# Google-Teachable-Machine-Project

<details>
<summary>출품 UCC영상</summary>
<div markdown="1"> 
https://drive.google.com/file/d/1HDjnWheEc7eM8prugSlrjqs3UkteXcV_/view?usp=sharing
</div>
</details>

<details>
<summary>Teachable Machine 사용</summary>
<div markdown="1"> 
https://teachablemachine.withgoogle.com/models/fCtu6At15/
</div>
</details>

<details>
<summary>감정, 인지 학습 구현</summary>
<div markdown="1"> 
https://awesome-hodgkin-47e8d6.netlify.app/
</div>
</details>

<details>
<summary>공모전 수상</summary>
<div markdown="1"> 
<image src="https://user-images.githubusercontent.com/83220871/140457746-62402183-7a3d-4b7b-842a-846298933771.jpg" width="300" height="400"/>
</div>
</details>

<details>
<summary>세상에서 가장 쉬운 인공지능 만들기 1, 2탄</summary>
<div markdown="1"> 
https://youtu.be/USQGTW34lO8
  
https://youtu.be/9SwdGFzFb5Y
</div>
</details>

#### Function

* Python을 통해 분노/놀람/기쁨/슬픔에 해당하는 이미지를 크롤링
* Teachable Machine을 통해 이미지 머신러닝 수행
* Webcam API 를 통해 실제 표정을 토대로 학습
* Google 음성 API를 통해 학습 시 음성출력
* Teachable Machine API를 토대로 감정학습 웹 페이지 구현1
* Teachable Machine API를 토대로 감정학습 웹 페이지 구현2


#### Comment

작업을 마치고 바로 Github에 올렸어야 하는데, 당시에는 생각을 못했다.

일부 코드가 날라가서 아쉽고, 막상 다시 보니까 구현 못했던 것들이 너무 많다.

웹페이지도 반응형으로 만들지 못해서 난해하고 복잡하다.

이미지 학습을 진행할 때 큰 동작 같은 것들은 잘 잡아냈지만, 표정변화 같은 것들은 쉽게 잡아내지 못했다.

최대한 표정변화를 알 수 있게끔 학습하려면 크롤링했던 이미지 파일 중에서 많은 선별이 필요했고,

이미지에 얼굴만 나와야 인식이 가능했다. (얼빡샷)

현재도 많이 부족하지만 맨 땅에 헤딩하는 느낌으로 친구와 같이 공모전을 나갔던 것이라 많은 것을 배우고, 좋은 경험을 했다고 생각한다.

무엇보다 심화된 학습을 하고, 아이트래커와 같은 장비를 사용하여 서비스화 된다면,

직접적으로 교육이 필요했던 사람들에게 도움을 줄 수 있을 것이라는 생각에 뿌듯했던 프로젝트였다.

